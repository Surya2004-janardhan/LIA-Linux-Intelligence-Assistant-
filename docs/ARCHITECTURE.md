# WIA Architecture ‚Äî Production System Design

## System Overview

WIA is a **local-first, multi-agent OS wrapper** that uses a local LLM to translate natural language into system actions. Every OS interaction passes through abstraction layers that enforce safety, permissions, and auditability.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     USER INTERFACES                             ‚îÇ
‚îÇ  CLI (WIA.py) ‚îÄ‚îÄ‚îÄ‚îÄ GUI (Flet) ‚îÄ‚îÄ‚îÄ‚îÄ TUI (Textual/Rich)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     ORCHESTRATOR                                ‚îÇ
‚îÇ  1. Context Engine ‚Üí injects CWD, CPU, Git, Docker state       ‚îÇ
‚îÇ  2. RAG Lookup ‚Üí retrieves past successful commands             ‚îÇ
‚îÇ  3. LLM Planning ‚Üí generates multi-step plan                   ‚îÇ
‚îÇ  4. Safety Guard ‚Üí validates commands before execution          ‚îÇ
‚îÇ  5. Feedback ‚Üí records results for future RAG                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   AGENT SWARM (9 specialists)                   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ FileAgent‚îÇ ‚îÇ SysAgent ‚îÇ ‚îÇ GitAgent ‚îÇ ‚îÇ NetAgent ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ WebAgent ‚îÇ ‚îÇConnection‚îÇ ‚îÇ Docker   ‚îÇ ‚îÇ Database ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  Agent   ‚îÇ ‚îÇ  Agent   ‚îÇ ‚îÇ  Agent   ‚îÇ         ‚îÇ
‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ Package  ‚îÇ     Each agent uses             ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ  Agent   ‚îÇ     Two-Tier Smart Routing      ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     (keyword ‚Üí LLM fallback)    ‚îÇ               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   CORE ENGINE LAYER                             ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ  OS Layer   ‚îÇ  ‚îÇ Permission  ‚îÇ  ‚îÇ   Safety     ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ (singleton) ‚îÇ  ‚îÇ  Manager    ‚îÇ  ‚îÇ   Guard      ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ signals   ‚îÇ  ‚îÇ ‚Ä¢ paths     ‚îÇ  ‚îÇ ‚Ä¢ blacklist  ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ subprocess‚îÇ  ‚îÇ ‚Ä¢ agents    ‚îÇ  ‚îÇ ‚Ä¢ dry-run    ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ platform  ‚îÇ  ‚îÇ ‚Ä¢ connections‚îÇ  ‚îÇ ‚Ä¢ risk tiers ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ cleanup   ‚îÇ  ‚îÇ ‚Ä¢ cache     ‚îÇ  ‚îÇ              ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ         ‚îÇ                ‚îÇ                ‚îÇ                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ  LLM Bridge ‚îÇ  ‚îÇ   Errors    ‚îÇ  ‚îÇ  Context     ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Ollama    ‚îÇ  ‚îÇ ‚Ä¢ 60+ codes ‚îÇ  ‚îÇ  Engine      ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ OpenAI    ‚îÇ  ‚îÇ ‚Ä¢ severity  ‚îÇ  ‚îÇ ‚Ä¢ CWD files  ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Groq      ‚îÇ  ‚îÇ ‚Ä¢ recovery  ‚îÇ  ‚îÇ ‚Ä¢ CPU/RAM    ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ litellm   ‚îÇ  ‚îÇ   hints     ‚îÇ  ‚îÇ ‚Ä¢ Git/Docker ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   PERSISTENCE LAYER                             ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ  Audit DB   ‚îÇ  ‚îÇ  Memory DB  ‚îÇ  ‚îÇ  Feedback DB ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ actions   ‚îÇ  ‚îÇ ‚Ä¢ knowledge ‚îÇ  ‚îÇ ‚Ä¢ history    ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ tokens    ‚îÇ  ‚îÇ ‚Ä¢ prompts   ‚îÇ  ‚îÇ ‚Ä¢ ratings    ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ status    ‚îÇ  ‚îÇ ‚Ä¢ facts     ‚îÇ  ‚îÇ ‚Ä¢ RAG index  ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îÇ
‚îÇ  ‚îÇ FAISS Index ‚îÇ  ‚îÇ  Config     ‚îÇ                              ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ vectors   ‚îÇ  ‚îÇ ‚Ä¢ YAML r/w  ‚îÇ                              ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ semantic  ‚îÇ  ‚îÇ ‚Ä¢ hot reload‚îÇ                              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Data Flow: "Why is my PC slow?"

```
1. USER  ‚Üí WIA.py ask "why is my PC slow?"
2. CLI   ‚Üí Orchestrator.run("why is my PC slow?")
3. CONTEXT ENGINE
   ‚îú‚îÄ Detects performance keywords ‚Üí gathers CPU, RAM, top processes
   ‚îú‚îÄ Gathers CWD file listing (always)
   ‚îî‚îÄ Returns: "[System] CPU: 89% | RAM: 94% | Top: chrome(45%)"
4. FEEDBACK RAG
   ‚îú‚îÄ Searches command_history for similar queries
   ‚îî‚îÄ Returns: "Past: 'check cpu' ‚Üí SysAgent, check_cpu ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê"
5. LLM PLANNING (1 call, ~300 tokens)
   ‚îú‚îÄ System prompt includes: agents + context + RAG hints
   ‚îî‚îÄ Returns: {"steps": [{"agent": "SysAgent", "task": "system_health"}]}
6. AGENT EXECUTION
   ‚îú‚îÄ SysAgent.smart_execute("system_health")
   ‚îú‚îÄ Tier 1: keyword "health" matches ‚Üí calls system_health() ‚Üí 0 tokens
   ‚îî‚îÄ Returns: "CPU: 89%, RAM: 94%, Top: chrome(45%)"
7. SAFETY: No command to validate (pure Python tool)
8. FEEDBACK: Records result, prompts user for rating
9. AUDIT: Logs agent, task, result, tokens, status
```

**Total cost: 1 LLM call (~300 tokens) + 0 agent tokens = ~300 tokens**  
**Traditional approach: 3 LLM calls (~1500 tokens)**

---

## Two-Tier Smart Routing

The core innovation that reduces token cost by ~70%.

```python
# Every agent inherits from base_agent.py:

def smart_execute(self, task: str) -> str:
    # TIER 1: Keyword match (0 tokens, <1ms)
    tool_name, confidence = self.match_tool_by_keywords(task)
    if tool_name and confidence >= 0.8:
        args = self.extract_args_from_task(task, tool_name)
        return self.tools[tool_name]["func"](**args)  # Direct call

    # TIER 2: LLM fallback (200+ tokens, 1-3 seconds)
    return self._llm_execute(task)
```

### Why This Works
- Simple tasks have strong keyword signals: "check RAM" ‚Üí keyword "ram" ‚Üí `check_ram()`
- Complex tasks need LLM reasoning: "make sure my system can handle a Node.js deployment"
- ~70% of real-world queries hit Tier 1

---

## OS Layer Abstraction

Every system interaction goes through `core/os_layer.py`:

```python
# Instead of:
subprocess.run(["ping", "-c", "4", "google.com"])  # Breaks on Windows

# Agents use:
os_layer.run_command(os_layer.get_ping_cmd("google.com"), timeout=15)
# Returns: {"success": True, "stdout": "...", "duration_ms": 234, "timed_out": False}
```

**Benefits:**
- Platform-correct commands (Linux/Windows/Mac)
- Structured results instead of raw stdout
- Timeout protection on all subprocesses
- Process lifecycle management (cleanup on shutdown)
- Signal handling for graceful shutdown

---

## Safety Pipeline

Commands pass through `core/safety.py` before execution:

```
Command ‚Üí SafetyGuard.validate_command()
  ‚îú‚îÄ BLOCKED (rm -rf /, mkfs, dd to /dev) ‚Üí Rejected, logged
  ‚îú‚îÄ HIGH_RISK (rm -rf, sudo rm, git push --force) ‚Üí Double confirm + dry-run offer
  ‚îî‚îÄ SAFE (ls, ping, git status) ‚Üí Proceed
```

Dry-run support: `rsync ‚Üí rsync --dry-run`, `apt ‚Üí apt --simulate`, `pip ‚Üí pip --dry-run`

---

## Permission Model

```
core/permissions.py (singleton)
  ‚îÇ
  ‚îú‚îÄ Path Whitelist (configurable, resolves symlinks)
  ‚îÇ   ~/Documents, ~/Downloads, ~/Desktop, ./
  ‚îÇ
  ‚îú‚îÄ Path Blacklist (hardcoded, never overridable)
  ‚îÇ   C:\Windows, /etc, /proc, /sys, /dev
  ‚îÇ
  ‚îú‚îÄ Agent Operation Scoping
  ‚îÇ   FileAgent  ‚Üí READ, WRITE, EXECUTE
  ‚îÇ   SysAgent   ‚Üí READ, EXECUTE
  ‚îÇ   DatabaseAgent ‚Üí READ only
  ‚îÇ
  ‚îî‚îÄ Connection Kill-Switches
      Gmail     ‚Üí OFF by default
      Calendar  ‚Üí OFF by default
      CustomAPI ‚Üí OFF by default
```

---

## Error System

Every error is typed with a code, severity, and recovery suggestion:

```python
# Instead of: return "Error: file not found"
# Agents use:
return str(WIAResult.fail(
    ErrorCode.FILE_NOT_FOUND,       # Code 201
    "File not found: report.pdf",   # Message
    severity=ErrorSeverity.MEDIUM,  # Severity
    suggestion="Check the path"     # Auto-generated if not provided
))

# Output:
# [FILE_NOT_FOUND] File not found: report.pdf
#   üí° Fix: Check the file path and try again
```

Error domains: Permission (1xx), File (2xx), Network (3xx), LLM (4xx), Agent (5xx), System (6xx), Config (7xx)

---

## Feedback Loop (RAG)

```
1. User runs: WIA ask "check disk space"
2. SysAgent executes ‚Üí "C: 85% used (50GB free)"
3. User rates: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
4. Stored in: memory/feedback.db

Next time someone asks "how much disk space do I have?":
1. RAG finds: "check disk space" ‚Üí SysAgent, check_disk, rating=5
2. Orchestrator adds this hint to LLM prompt
3. LLM knows exactly which agent/tool to use ‚Üí faster, cheaper
```

---

## File Map

| File | Purpose | Lines |
|------|---------|-------|
| `WIA.py` | Entry point, CLI commands, rich output | ~190 |
| `core/orchestrator.py` | Plan + execute with context/RAG | ~130 |
| `core/os_layer.py` | OS abstraction, signals, subprocess | ~200 |
| `core/safety.py` | Destructive command guardrails | ~130 |
| `core/permissions.py` | Path/agent/connection access control | ~160 |
| `core/context_engine.py` | Dynamic system state injection | ~130 |
| `core/feedback.py` | Command history, ratings, RAG | ~170 |
| `core/errors.py` | Typed error codes + recovery hints | ~120 |
| `core/explain.py` | Command breakdown engine | ~100 |
| `core/llm_bridge.py` | LLM abstraction (Ollama/OpenAI) | ~60 |
| `core/audit.py` | Full audit trail with token tracking | ~55 |
| `core/memory_manager.py` | Central memory + system prompts | ~100 |
| `core/config.py` | Read/write YAML config | ~30 |
| `agents/base_agent.py` | Two-tier smart routing base class | ~100 |
| `agents/*.py` | 9 specialist agents | ~80 each |

---

## Adding a New Agent (5 minutes)

1. Create `agents/your_agent.py`, extend `WIAAgent`
2. Register tools with keywords in `__init__`
3. Implement `extract_args_from_task()` for regex extraction
4. Call `self.smart_execute(task)` in `execute()`
5. Import and add to the agents list in `WIA.py`

The Orchestrator auto-discovers it. No routing rules to update.

---

## Scalability Path

| Feature | Current | Next |
|---------|---------|------|
| Agents | 9 (sync) | Plugin system, lazy loading |
| LLM | Ollama local | Streaming, multi-provider routing |
| RAG | SQLite keyword search | FAISS vector similarity |
| Execution | Sequential + basic async | True async with dependency graphs |
| Packaging | pip install | .deb, .rpm, PKGBUILD, Homebrew |
